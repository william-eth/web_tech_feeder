# GitHub Personal Access Token (for higher API rate limits)
GITHUB_TOKEN=ghp_xxxxx

# === AI Provider ===
# Choose: "gemini" (default) or "openai" (OpenRouter/Groq/Ollama/etc.)
AI_PROVIDER=gemini

# --- Option A: Gemini (default) ---
GEMINI_API_KEY=AIzaSyxxxxx
# GEMINI_MODEL=gemini-2.0-flash-lite

# --- Option B: OpenAI-compatible API ---
# Works with: OpenRouter, Groq, Together AI, local Ollama, OpenAI
# AI_PROVIDER=openai
# AI_API_URL=https://openrouter.ai/api/v1
# AI_API_KEY=sk-or-xxxxx
# AI_MODEL=google/gemini-2.0-flash-exp:free
#
# Popular free models on OpenRouter:
#   google/gemini-2.0-flash-exp:free
#   meta-llama/llama-3.3-70b-instruct:free
#   qwen/qwen-2.5-72b-instruct:free
#
# Groq (fast, generous free tier):
#   AI_API_URL=https://api.groq.com/openai/v1
#   AI_API_KEY=gsk_xxxxx
#   AI_MODEL=llama-3.3-70b-versatile
#
# Local Ollama (no API key needed):
#   AI_API_URL=http://localhost:11434/v1
#   AI_MODEL=llama3.2

# Local preview: set true to skip email, save HTML to tmp/digest_preview.html
# DRY_RUN=true

# Gmail OAuth 2.0 (no password; use refresh token)
# Obtain via Google Cloud Console OAuth 2.0 + OAuth 2.0 Playground or one-time flow
GMAIL_CLIENT_ID=xxxx.apps.googleusercontent.com
GMAIL_CLIENT_SECRET=xxxx
GMAIL_REFRESH_TOKEN=xxxx

# Email (sender must match Gmail account used for OAuth)
EMAIL_FROM=your_email@gmail.com
# Single or multiple recipients (comma or semicolon separated)
EMAIL_TO=recipient@example.com
# EMAIL_TO=user1@example.com, user2@example.com
# BCC (optional, comma or semicolon separated)
# EMAIL_BCC=archive@example.com, backup@example.com

# Max completion tokens. Reasoning models (e.g. nvidia/nemotron) need 16384+;
# 8192 often leaves no room for actual output after internal reasoning.
# AI_MAX_TOKENS=16384

# Some models (GPT-5.x, o1, o3) require max_completion_tokens instead of max_tokens.
# Auto-detected for gpt-5*, o1-*, o3-*; set true to force for other models.
# AI_USE_MAX_COMPLETION_TOKENS=true

# Digest filtering: minimum importance to include
# "high" (default) = critical + high | "medium" = + Issue/PR/Blog | "low" = all
# Each category reserves 2 slots for Issue/PR/Blog when AI returns them
# DIGEST_MIN_IMPORTANCE=high
